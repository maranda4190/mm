#!/usr/bin/env python3
"""
AIæŠ•èµ„æ–°é—»ç›‘æ§ç³»ç»Ÿ - å‘½ä»¤è¡Œå·¥å…·
"""

import asyncio
import sys
import os
import argparse
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

async def fetch_news():
    """æ‰‹åŠ¨è·å–æ–°é—»"""
    print("ğŸ” å¼€å§‹è·å–æœ€æ–°æ–°é—»...")
    
    try:
        from scraper import NewsFetcher
        from analyzer import NewsAnalyzer
        from database import init_database, AsyncSessionLocal, NewsArticle
        
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_database()
        
        # è·å–æ–°é—»
        async with NewsFetcher() as fetcher:
            news_list = await fetcher.fetch_all_news()
        
        print(f"ğŸ“° è·å–åˆ° {len(news_list)} æ¡ç›¸å…³æ–°é—»")
        
        if not news_list:
            print("ğŸ˜´ æš‚æ— æ–°çš„AIæŠ•èµ„æ–°é—»")
            return
        
        # åˆ†ææ–°é—»
        analyzer = NewsAnalyzer()
        analyzed_news = await analyzer.analyze_news_batch(news_list)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        async with AsyncSessionLocal() as db:
            saved_count = 0
            for news_data in analyzed_news:
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    from sqlalchemy import select
                    existing_query = select(NewsArticle).where(NewsArticle.link == news_data['link'])
                    existing_result = await db.execute(existing_query)
                    existing_article = existing_result.scalar_one_or_none()
                    
                    if existing_article:
                        continue
                    
                    # åˆ›å»ºæ–°é—»è®°å½•
                    analysis = news_data.get('analysis', {})
                    article = NewsArticle(
                        title=news_data.get('title', ''),
                        link=news_data.get('link', ''),
                        summary=news_data.get('summary', ''),
                        content=news_data.get('content', ''),
                        published_date=news_data.get('published_date'),
                        source=news_data.get('source', ''),
                        source_url=news_data.get('source_url', ''),
                        author=news_data.get('author', ''),
                        tags=news_data.get('tags', []),
                        analysis=analysis,
                        relevance_score=analysis.get('relevance_score', 0.0),
                        importance_score=analysis.get('importance_score', 0.0),
                        overall_score=analysis.get('overall_score', 0.0),
                        category=analysis.get('category', 'general'),
                        urgency=analysis.get('urgency', 'low'),
                        analyzed_at=datetime.utcnow(),
                        is_processed=True
                    )
                    
                    db.add(article)
                    saved_count += 1
                    
                except Exception as e:
                    print(f"âš ï¸  ä¿å­˜å¤±è´¥: {e}")
                    continue
            
            await db.commit()
            print(f"ğŸ’¾ æˆåŠŸä¿å­˜ {saved_count} æ¡æ–°æ–°é—»")
        
    except Exception as e:
        print(f"âŒ è·å–æ–°é—»å¤±è´¥: {e}")

async def show_stats():
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    print("ğŸ“Š ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯")
    print("-" * 30)
    
    try:
        from database import AsyncSessionLocal, NewsArticle, TrendingTopic
        from sqlalchemy import select, func
        
        async with AsyncSessionLocal() as db:
            # æ€»æ–°é—»æ•°
            total_query = select(func.count(NewsArticle.id))
            total_result = await db.execute(total_query)
            total_count = total_result.scalar() or 0
            
            # ä»Šæ—¥æ–°é—»
            today = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)
            today_query = select(func.count(NewsArticle.id)).where(
                NewsArticle.published_date >= today
            )
            today_result = await db.execute(today_query)
            today_count = today_result.scalar() or 0
            
            # é‡è¦æ–°é—»
            important_query = select(func.count(NewsArticle.id)).where(
                NewsArticle.importance_score >= 0.7
            )
            important_result = await db.execute(important_query)
            important_count = important_result.scalar() or 0
            
            # æŠ•èµ„äº‹ä»¶
            investment_query = select(func.count(NewsArticle.id)).where(
                NewsArticle.category.in_(['funding', 'acquisition', 'ipo'])
            )
            investment_result = await db.execute(investment_query)
            investment_count = investment_result.scalar() or 0
            
            # çƒ­é—¨è¯é¢˜
            trending_query = select(func.count(TrendingTopic.id))
            trending_result = await db.execute(trending_query)
            trending_count = trending_result.scalar() or 0
            
            print(f"ğŸ“° æ€»æ–°é—»æ•°é‡: {total_count}")
            print(f"ğŸ“… ä»Šæ—¥æ–°é—»: {today_count}")
            print(f"â­ é‡è¦æ–°é—»: {important_count}")
            print(f"ğŸ’° æŠ•èµ„äº‹ä»¶: {investment_count}")
            print(f"ğŸ”¥ çƒ­é—¨è¯é¢˜: {trending_count}")
            
    except Exception as e:
        print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

async def show_latest_news(limit=10):
    """æ˜¾ç¤ºæœ€æ–°æ–°é—»"""
    print(f"ğŸ“° æœ€æ–° {limit} æ¡æ–°é—»")
    print("-" * 50)
    
    try:
        from database import AsyncSessionLocal, NewsArticle
        from sqlalchemy import select, desc
        
        async with AsyncSessionLocal() as db:
            query = select(NewsArticle).order_by(desc(NewsArticle.published_date)).limit(limit)
            result = await db.execute(query)
            news_articles = result.scalars().all()
            
            for i, article in enumerate(news_articles, 1):
                print(f"{i}. {article.title[:80]}...")
                print(f"   ğŸ“… {article.published_date.strftime('%Y-%m-%d %H:%M') if article.published_date else 'N/A'}")
                print(f"   ğŸ”— {article.source}")
                if article.analysis:
                    print(f"   â­ é‡è¦æ€§: {article.importance_score:.2f} | åˆ†ç±»: {article.category}")
                print()
            
    except Exception as e:
        print(f"âŒ è·å–æ–°é—»å¤±è´¥: {e}")

async def cleanup_old_data(days=30):
    """æ¸…ç†æ—§æ•°æ®"""
    print(f"ğŸ§¹ æ¸…ç† {days} å¤©å‰çš„æ•°æ®...")
    
    try:
        from database import AsyncSessionLocal, NewsArticle, TrendingTopic
        from sqlalchemy import delete
        
        cutoff_date = datetime.utcnow() - timedelta(days=days)
        
        async with AsyncSessionLocal() as db:
            # åˆ é™¤æ—§æ–°é—»ï¼ˆä¿ç•™é‡è¦æ–°é—»ï¼‰
            delete_news_query = delete(NewsArticle).where(
                (NewsArticle.published_date < cutoff_date) &
                (NewsArticle.importance_score < 0.8)
            )
            news_result = await db.execute(delete_news_query)
            
            # åˆ é™¤æ—§çƒ­é—¨è¯é¢˜
            delete_trending_query = delete(TrendingTopic).where(
                TrendingTopic.latest_mention < cutoff_date
            )
            trending_result = await db.execute(delete_trending_query)
            
            await db.commit()
            
            print(f"ğŸ—‘ï¸  åˆ é™¤äº† {news_result.rowcount} æ¡æ—§æ–°é—»")
            print(f"ğŸ—‘ï¸  åˆ é™¤äº† {trending_result.rowcount} ä¸ªæ—§è¯é¢˜")
        
    except Exception as e:
        print(f"âŒ æ¸…ç†æ•°æ®å¤±è´¥: {e}")

def main():
    parser = argparse.ArgumentParser(description="AIæŠ•èµ„æ–°é—»ç›‘æ§ç³»ç»ŸCLIå·¥å…·")
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # è·å–æ–°é—»å‘½ä»¤
    fetch_parser = subparsers.add_parser('fetch', help='æ‰‹åŠ¨è·å–æ–°é—»')
    
    # æ˜¾ç¤ºç»Ÿè®¡å‘½ä»¤
    stats_parser = subparsers.add_parser('stats', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    
    # æ˜¾ç¤ºæœ€æ–°æ–°é—»å‘½ä»¤
    news_parser = subparsers.add_parser('news', help='æ˜¾ç¤ºæœ€æ–°æ–°é—»')
    news_parser.add_argument('--limit', type=int, default=10, help='æ˜¾ç¤ºæ•°é‡')
    
    # æ¸…ç†æ•°æ®å‘½ä»¤
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ—§æ•°æ®')
    cleanup_parser.add_argument('--days', type=int, default=30, help='ä¿ç•™å¤©æ•°')
    
    # æµ‹è¯•å‘½ä»¤
    test_parser = subparsers.add_parser('test', help='è¿è¡Œç³»ç»Ÿæµ‹è¯•')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    print("ğŸ¤– AIæŠ•èµ„æ–°é—»ç›‘æ§CLI")
    print("=" * 40)
    
    try:
        if args.command == 'fetch':
            asyncio.run(fetch_news())
        elif args.command == 'stats':
            asyncio.run(show_stats())
        elif args.command == 'news':
            asyncio.run(show_latest_news(args.limit))
        elif args.command == 'cleanup':
            asyncio.run(cleanup_old_data(args.days))
        elif args.command == 'test':
            from test_system import main as test_main
            asyncio.run(test_main())
            
    except KeyboardInterrupt:
        print("\næ“ä½œå·²ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æ“ä½œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()